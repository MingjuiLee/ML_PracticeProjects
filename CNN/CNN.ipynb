{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "# Importing the libraries\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "print(tf.__version__)\n",
    "import numpy as np\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing the Training set\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "        'dataset/training_set',\n",
    "        target_size=(64, 64),  # make training much faster\n",
    "        batch_size=32,  # how many images in each batch, 32 is a classic default\n",
    "        class_mode='binary')  # cat, dog: binary\n",
    "\n",
    "# Preprocessing the Test set\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "        'dataset/test_set',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - Building the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the CNN\n",
    "cnn = tf.keras.models.Sequential()  # an object as sequence of layers\n",
    "\n",
    "# Step 1 - Convolution, use add method to add layer\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32,\n",
    "                              kernel_size=3,\n",
    "                              activation='relu',\n",
    "                              input_shape=[64, 64, 3]))\n",
    "\n",
    "# Step 2 - Pooling (Max Pooling)\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "# Adding a second convolutional layer\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32,\n",
    "                               kernel_size=3,\n",
    "                               activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "# Step 3 - Flattening\n",
    "cnn.add(tf.keras.layers.Flatten())\n",
    "\n",
    "# # Step 4 - Full Connection\n",
    "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
    "\n",
    "# Step 5 - Output Layer\n",
    "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 - Training the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "250/250 [==============================] - 40s 160ms/step - loss: 0.6718 - accuracy: 0.5755 - val_loss: 0.6259 - val_accuracy: 0.6590\n",
      "Epoch 2/25\n",
      "250/250 [==============================] - 42s 167ms/step - loss: 0.6041 - accuracy: 0.6725 - val_loss: 0.6049 - val_accuracy: 0.6775\n",
      "Epoch 3/25\n",
      "250/250 [==============================] - 39s 157ms/step - loss: 0.5519 - accuracy: 0.7207 - val_loss: 0.5790 - val_accuracy: 0.7040\n",
      "Epoch 4/25\n",
      "250/250 [==============================] - 39s 155ms/step - loss: 0.5127 - accuracy: 0.7455 - val_loss: 0.5924 - val_accuracy: 0.7170\n",
      "Epoch 5/25\n",
      "250/250 [==============================] - 35s 142ms/step - loss: 0.4952 - accuracy: 0.7596 - val_loss: 0.5154 - val_accuracy: 0.7490\n",
      "Epoch 6/25\n",
      "250/250 [==============================] - 38s 153ms/step - loss: 0.4753 - accuracy: 0.7715 - val_loss: 0.5537 - val_accuracy: 0.7430\n",
      "Epoch 7/25\n",
      "250/250 [==============================] - 41s 162ms/step - loss: 0.4663 - accuracy: 0.7751 - val_loss: 0.5517 - val_accuracy: 0.7305\n",
      "Epoch 8/25\n",
      "250/250 [==============================] - 41s 163ms/step - loss: 0.4516 - accuracy: 0.7876 - val_loss: 0.4731 - val_accuracy: 0.7785\n",
      "Epoch 9/25\n",
      "250/250 [==============================] - 39s 157ms/step - loss: 0.4411 - accuracy: 0.7901 - val_loss: 0.5465 - val_accuracy: 0.7335\n",
      "Epoch 10/25\n",
      "250/250 [==============================] - 35s 141ms/step - loss: 0.4181 - accuracy: 0.8046 - val_loss: 0.4679 - val_accuracy: 0.7850\n",
      "Epoch 11/25\n",
      "250/250 [==============================] - 40s 158ms/step - loss: 0.4079 - accuracy: 0.8076 - val_loss: 0.4711 - val_accuracy: 0.7730\n",
      "Epoch 12/25\n",
      "250/250 [==============================] - 40s 162ms/step - loss: 0.3980 - accuracy: 0.8163 - val_loss: 0.4725 - val_accuracy: 0.7785\n",
      "Epoch 13/25\n",
      "250/250 [==============================] - 42s 168ms/step - loss: 0.3813 - accuracy: 0.8284 - val_loss: 0.5077 - val_accuracy: 0.7710\n",
      "Epoch 14/25\n",
      "250/250 [==============================] - 40s 161ms/step - loss: 0.3661 - accuracy: 0.8376 - val_loss: 0.5212 - val_accuracy: 0.7570\n",
      "Epoch 15/25\n",
      "250/250 [==============================] - 44s 176ms/step - loss: 0.3395 - accuracy: 0.8500 - val_loss: 0.5088 - val_accuracy: 0.7780\n",
      "Epoch 16/25\n",
      "250/250 [==============================] - 43s 172ms/step - loss: 0.3325 - accuracy: 0.8550 - val_loss: 0.4832 - val_accuracy: 0.7845\n",
      "Epoch 17/25\n",
      "250/250 [==============================] - 32s 129ms/step - loss: 0.3223 - accuracy: 0.8568 - val_loss: 0.4833 - val_accuracy: 0.7935\n",
      "Epoch 18/25\n",
      "250/250 [==============================] - 31s 126ms/step - loss: 0.2947 - accuracy: 0.8767 - val_loss: 0.5480 - val_accuracy: 0.7630\n",
      "Epoch 19/25\n",
      "250/250 [==============================] - 31s 125ms/step - loss: 0.2890 - accuracy: 0.8754 - val_loss: 0.5184 - val_accuracy: 0.7945\n",
      "Epoch 20/25\n",
      "250/250 [==============================] - 31s 126ms/step - loss: 0.2713 - accuracy: 0.8834 - val_loss: 0.5027 - val_accuracy: 0.7960\n",
      "Epoch 21/25\n",
      "250/250 [==============================] - 32s 128ms/step - loss: 0.2574 - accuracy: 0.8920 - val_loss: 0.5767 - val_accuracy: 0.7680\n",
      "Epoch 22/25\n",
      "250/250 [==============================] - 33s 133ms/step - loss: 0.2528 - accuracy: 0.8926 - val_loss: 0.5163 - val_accuracy: 0.8060\n",
      "Epoch 23/25\n",
      "250/250 [==============================] - 35s 139ms/step - loss: 0.2310 - accuracy: 0.9025 - val_loss: 0.5523 - val_accuracy: 0.7910\n",
      "Epoch 24/25\n",
      "250/250 [==============================] - 34s 137ms/step - loss: 0.2180 - accuracy: 0.9125 - val_loss: 0.5343 - val_accuracy: 0.8040\n",
      "Epoch 25/25\n",
      "250/250 [==============================] - 34s 137ms/step - loss: 0.2042 - accuracy: 0.9201 - val_loss: 0.5850 - val_accuracy: 0.7950\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9cbcaacf50>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compiling the CNN\n",
    "cnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Training the CNN on the Training set and evaluating it on the Test set\n",
    "cnn.fit(x=training_set, validation_data=test_set, epochs=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4 - Making a single prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array [[[ 54.  58.   7.]\n",
      "  [ 58.  63.   9.]\n",
      "  [ 64.  67.  10.]\n",
      "  ...\n",
      "  [136. 144.  71.]\n",
      "  [140. 150.  77.]\n",
      "  [139. 149.  78.]]\n",
      "\n",
      " [[ 48.  54.   6.]\n",
      "  [ 51.  58.   7.]\n",
      "  [ 58.  63.   9.]\n",
      "  ...\n",
      "  [129. 137.  64.]\n",
      "  [139. 149.  78.]\n",
      "  [141. 151.  80.]]\n",
      "\n",
      " [[ 48.  56.   7.]\n",
      "  [ 48.  56.   7.]\n",
      "  [ 54.  61.  10.]\n",
      "  ...\n",
      "  [123. 130.  63.]\n",
      "  [136. 145.  80.]\n",
      "  [140. 149.  82.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 46.  55.  12.]\n",
      "  [ 42.  50.   9.]\n",
      "  [ 38.  49.   9.]\n",
      "  ...\n",
      "  [239. 205. 170.]\n",
      "  [235. 209. 186.]\n",
      "  [229. 202. 173.]]\n",
      "\n",
      " [[ 50.  57.  15.]\n",
      "  [ 42.  50.   9.]\n",
      "  [ 44.  52.  11.]\n",
      "  ...\n",
      "  [234. 200. 162.]\n",
      "  [236. 206. 178.]\n",
      "  [234. 203. 174.]]\n",
      "\n",
      " [[ 53.  59.  13.]\n",
      "  [ 43.  51.  10.]\n",
      "  [ 49.  56.  12.]\n",
      "  ...\n",
      "  [231. 195. 159.]\n",
      "  [235. 213. 190.]\n",
      "  [233. 206. 179.]]]\n",
      "Vector [[[[ 54.  58.   7.]\n",
      "   [ 58.  63.   9.]\n",
      "   [ 64.  67.  10.]\n",
      "   ...\n",
      "   [136. 144.  71.]\n",
      "   [140. 150.  77.]\n",
      "   [139. 149.  78.]]\n",
      "\n",
      "  [[ 48.  54.   6.]\n",
      "   [ 51.  58.   7.]\n",
      "   [ 58.  63.   9.]\n",
      "   ...\n",
      "   [129. 137.  64.]\n",
      "   [139. 149.  78.]\n",
      "   [141. 151.  80.]]\n",
      "\n",
      "  [[ 48.  56.   7.]\n",
      "   [ 48.  56.   7.]\n",
      "   [ 54.  61.  10.]\n",
      "   ...\n",
      "   [123. 130.  63.]\n",
      "   [136. 145.  80.]\n",
      "   [140. 149.  82.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 46.  55.  12.]\n",
      "   [ 42.  50.   9.]\n",
      "   [ 38.  49.   9.]\n",
      "   ...\n",
      "   [239. 205. 170.]\n",
      "   [235. 209. 186.]\n",
      "   [229. 202. 173.]]\n",
      "\n",
      "  [[ 50.  57.  15.]\n",
      "   [ 42.  50.   9.]\n",
      "   [ 44.  52.  11.]\n",
      "   ...\n",
      "   [234. 200. 162.]\n",
      "   [236. 206. 178.]\n",
      "   [234. 203. 174.]]\n",
      "\n",
      "  [[ 53.  59.  13.]\n",
      "   [ 43.  51.  10.]\n",
      "   [ 49.  56.  12.]\n",
      "   ...\n",
      "   [231. 195. 159.]\n",
      "   [235. 213. 190.]\n",
      "   [233. 206. 179.]]]]\n",
      "{'cats': 0, 'dogs': 1}\n",
      "Single Prediction:  dog\n"
     ]
    }
   ],
   "source": [
    "test_image = image.load_img('dataset/single_prediction/cat_or_dog_1.jpg', target_size=(64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "print(\"Array\", test_image)\n",
    "test_image = np.expand_dims(test_image, axis=0)\n",
    "print(\"Vector\", test_image)\n",
    "result = cnn.predict(test_image)\n",
    "print(training_set.class_indices)\n",
    "\n",
    "# Encoding to specify which is 1 and which is 0\n",
    "if result[0][0] == 1:\n",
    "    prediction = 'dog'\n",
    "else:\n",
    "    prediction = 'cat'\n",
    "print(\"Single Prediction: \", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cats': 0, 'dogs': 1}\n",
      "Single Prediction:  dog\n"
     ]
    }
   ],
   "source": [
    "test_image = image.load_img('dataset/single_prediction/cat_or_dog_2.jpg', target_size=(64, 64))\n",
    "\n",
    "test_image = np.expand_dims(test_image, axis=0)\n",
    "\n",
    "result = cnn.predict(test_image)\n",
    "print(training_set.class_indices)\n",
    "\n",
    "# Encoding to specify which is 1 and which is 0\n",
    "if result[0][0] == 1:\n",
    "    prediction = 'dog'\n",
    "else:\n",
    "    prediction = 'cat'\n",
    "    \n",
    "print(\"Single Prediction: \", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cats': 0, 'dogs': 1}\n",
      "Single Prediction:  dog\n"
     ]
    }
   ],
   "source": [
    "test_image = image.load_img('dataset/single_prediction/cat_or_dog_3.jpg', target_size=(64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "\n",
    "test_image = np.expand_dims(test_image, axis=0)\n",
    "\n",
    "result = cnn.predict(test_image)\n",
    "print(training_set.class_indices)\n",
    "\n",
    "# Encoding to specify which is 1 and which is 0\n",
    "if result[0][0] == 1:\n",
    "    prediction = 'dog'\n",
    "else:\n",
    "    prediction = 'cat'\n",
    "print(\"Single Prediction: \", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cats': 0, 'dogs': 1}\n",
      "Single Prediction:  cat\n"
     ]
    }
   ],
   "source": [
    "test_image = image.load_img('dataset/single_prediction/cat_or_dog_4.jpg', target_size=(64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "\n",
    "test_image = np.expand_dims(test_image, axis=0)\n",
    "\n",
    "result = cnn.predict(test_image)\n",
    "print(training_set.class_indices)\n",
    "\n",
    "# Encoding to specify which is 1 and which is 0\n",
    "if result[0][0] == 1:\n",
    "    prediction = 'dog'\n",
    "else:\n",
    "    prediction = 'cat'\n",
    "print(\"Single Prediction: \", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
